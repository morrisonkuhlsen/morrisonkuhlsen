---
layout: page
title: Testes de Hip√≥tese
lang: pt
ref: testes-hipotese
parent: inferencia-estatistica
permalink: /pt/inferencia-estatistica/testes-hipotese
order: 1
---

Os **Testes de Hip√≥tese** s√£o procedimentos estat√≠sticos que nos permitem tomar decis√µes sobre par√¢metros populacionais com base em dados amostrais. S√£o ferramentas fundamentais para a infer√™ncia estat√≠stica e tomada de decis√µes baseadas em evid√™ncias.

<div style="border-left: 4px solid #4CAF50; padding: 0.5em; background-color: #e8f5e9;">
  <strong>üéØ Importante:</strong><br>
  Um teste de hip√≥tese envolve duas hip√≥teses:
  - A hip√≥tese nula ($H_0$): afirma√ß√£o inicial que assumimos como verdadeira
  - A hip√≥tese alternativa ($H_1$ ou $H_a$): afirma√ß√£o que contradiz $H_0$
</div>

## 1. Conceitos Fundamentais

### 1.1 Estrutura B√°sica

Um teste de hip√≥tese segue uma estrutura sistem√°tica:

1. **Formula√ß√£o das Hip√≥teses**
   - Hip√≥tese nula ($H_0$)

   - Hip√≥tese alternativa ($$H_1$$)

2. **N√≠vel de Signific√¢ncia ($$\alpha$$)**
   - Probabilidade de erro tipo I
   - Geralmente 5% ou 1%

3. **Estat√≠stica de Teste**
   - Medida calculada a partir dos dados
   - Base para a decis√£o

4. **Regi√£o Cr√≠tica**
   - Valores que levam √† rejei√ß√£o de $$H_0$$
   - Determinada por $$\alpha$$

### 1.2 Tipos de Erro

![Tipos de erro em testes de hip√≥tese]({{ site.baseurl }}/assets/images/erros-teste.png){:style="max-width: 400px; display: block; margin: 0 auto;"}
<div class="image-caption" style="text-align: center;">Figura: Matriz de decis√£o e tipos de erro em testes de hip√≥tese</div>

| Decis√£o vs. Realidade | $$H_0$$ Verdadeira | $$H_0$$ Falsa |
|----------------------|-------------------|---------------|
| Rejeitar $$H_0$$    | Erro Tipo I ($$\alpha$$) | Decis√£o Correta |
| N√£o Rejeitar $$H_0$$| Decis√£o Correta | Erro Tipo II ($$\beta$$) |

## 2. Etapas do Teste de Hip√≥tese

### 2.1 Formula√ß√£o das Hip√≥teses

<div class="code-container">
  <div class="code-header">
    <div class="code-lang">julia</div>
    <div style="flex-grow: 1;"></div>
    <button class="copy-button" onclick="copyCode(this)">
      <i class="bi bi-clipboard"></i>Copiar
    </button>
  </div>
  <div class="code-content">
    <pre><code>using HypothesisTests

# Exemplo: Teste para m√©dia populacional
function exemplo_teste_media()
    # Dados simulados
    dados = randn(100) .+ 0.5  # Amostra normal com m√©dia 0.5
    
    # Teste t de uma amostra
    teste = OneSampleTTest(dados)
    
    println("Teste t para m√©dia populacional")
    println("-------------------------------")
    println("H‚ÇÄ: Œº = 0")
    println("H‚ÇÅ: Œº ‚â† 0")
    println("Estat√≠stica t = ", round(test_statistic(teste), digits=4))
    println("Valor-p = ", round(pvalue(teste), digits=4))
end

exemplo_teste_media()</code></pre>
  </div>
</div>

### 2.2 Escolha do N√≠vel de Signific√¢ncia

O n√≠vel de signific√¢ncia ($$\alpha$$) √© a probabilidade m√°xima aceit√°vel de cometer um erro tipo I:

- $$\alpha = 0,05$$ (5%): N√≠vel comum em ci√™ncias sociais
- $$\alpha = 0,01$$ (1%): Usado quando necess√°ria maior confian√ßa
- $$\alpha = 0,10$$ (10%): Usado em estudos preliminares

### 2.3 C√°lculo da Estat√≠stica de Teste

A estat√≠stica de teste √© uma medida padronizada que segue uma distribui√ß√£o conhecida sob $$H_0$$:

1. **Teste Z**
   $$Z = \frac{\bar{X} - \mu_0}{\sigma/\sqrt{n}}$$

2. **Teste t**
   $$t = \frac{\bar{X} - \mu_0}{s/\sqrt{n}}$$

3. **Teste Qui-quadrado**
   $$\chi^2 = \sum_{i=1}^k \frac{(O_i - E_i)^2}{E_i}$$

## 3. Valor-p e Tomada de Decis√£o

### 3.1 Interpreta√ß√£o do Valor-p

![Interpreta√ß√£o do valor-p]({{ site.baseurl }}/assets/images/valor-p.png){:style="max-width: 400px; display: block; margin: 0 auto;"}
<div class="image-caption" style="text-align: center;">Figura: Representa√ß√£o gr√°fica do valor-p em uma distribui√ß√£o normal</div>

O valor-p √© a probabilidade de obter uma estat√≠stica de teste t√£o ou mais extrema que a observada, assumindo $$H_0$$ verdadeira:

- Se valor-p $$\leq \alpha$$: Rejeita-se $$H_0$$
- Se valor-p $$> \alpha$$: N√£o se rejeita $$H_0$$

### 3.2 Poder do Teste

O poder do teste ($$1-\beta$$) √© a probabilidade de rejeitar $$H_0$$ quando ela √© falsa:

<div class="code-container">
  <div class="code-header">
    <div class="code-lang">julia</div>
    <div style="flex-grow: 1;"></div>
    <button class="copy-button" onclick="copyCode(this)">
      <i class="bi bi-clipboard"></i>Copiar
    </button>
  </div>
  <div class="code-content">
    <pre><code>using Distributions

function calcular_poder_teste()
    # Par√¢metros
    n = 30  # Tamanho da amostra
    Œ± = 0.05  # N√≠vel de signific√¢ncia
    Œº‚ÇÄ = 0  # M√©dia sob H‚ÇÄ
    Œº‚Çê = 0.5  # M√©dia sob H‚ÇÅ
    œÉ = 1  # Desvio padr√£o
    
    # Valor cr√≠tico
    z_crit = quantile(Normal(), 1-Œ±/2)
    
    # Poder do teste
    Œ≤ = cdf(Normal(), z_crit - (Œº‚Çê-Œº‚ÇÄ)/(œÉ/‚àön)) - 
        cdf(Normal(), -z_crit - (Œº‚Çê-Œº‚ÇÄ)/(œÉ/‚àön))
    poder = 1 - Œ≤
    
    println("An√°lise do Poder do Teste")
    println("-------------------------")
    println("Tamanho da amostra = ", n)
    println("N√≠vel de signific√¢ncia = ", Œ±)
    println("Poder do teste = ", round(poder, digits=4))
end

calcular_poder_teste()</code></pre>
  </div>
</div>

## 4. Tipos de Testes de Hip√≥tese

### 4.1 Testes Param√©tricos

1. **Teste Z**
   - Para m√©dias com œÉ conhecido
   - Amostras grandes (n ‚â• 30)

2. **Teste t**
   - Para m√©dias com œÉ desconhecido
   - Uma ou duas amostras
   - Amostras pareadas

3. **Teste F**
   - Compara√ß√£o de vari√¢ncias
   - ANOVA

### 4.2 Testes N√£o-Param√©tricos

1. **Teste de Wilcoxon**
   - Alternativa ao teste t
   - N√£o assume normalidade

2. **Teste de Mann-Whitney**
   - Compara√ß√£o de duas popula√ß√µes
   - Dados ordinais

3. **Teste Qui-quadrado**
   - Independ√™ncia
   - Ader√™ncia

## 5. Exerc√≠cios Resolvidos

### 5.1 Teste para M√©dia Populacional

![Exemplo de teste de hip√≥tese]({{ site.baseurl }}/assets/images/teste-media.png){:style="max-width: 400px; display: block; margin: 0 auto;"}
<div class="image-caption" style="text-align: center;">Figura: Distribui√ß√£o amostral e regi√µes cr√≠ticas</div>

> **Problema**: Uma empresa afirma que o tempo m√©dio de atendimento ao cliente √© de 10 minutos. Um analista coletou uma amostra de 36 atendimentos e encontrou uma m√©dia de 11,2 minutos com desvio padr√£o de 2,4 minutos. Ao n√≠vel de signific√¢ncia de 5%, h√° evid√™ncias para rejeitar a afirma√ß√£o da empresa?

**Dados**:
- $$H_0: \mu = 10$$ minutos
- $$H_1: \mu \neq 10$$ minutos
- $$\bar{x} = 11,2$$ minutos
- $$s = 2,4$$ minutos
- $$n = 36$$
- $$\alpha = 0,05$$

**Solu√ß√£o**:

1. Estat√≠stica de teste:
   $$t = \frac{\bar{x} - \mu_0}{s/\sqrt{n}} = \frac{11,2 - 10}{2,4/\sqrt{36}} = 3$$

2. Valor cr√≠tico (bilateral):
   $$t_{0,025;35} = \pm 2,03$$

3. Decis√£o:
   Como |3| > 2,03, rejeitamos $$H_0$$.

<div class="code-container">
  <div class="code-header">
    <div class="code-lang">julia</div>
    <div style="flex-grow: 1;"></div>
    <button class="copy-button" onclick="copyCode(this)">
      <i class="bi bi-clipboard"></i>Copiar
    </button>
  </div>
  <div class="code-content">
    <pre><code>function teste_tempo_atendimento()
    # Dados
    xÃÑ = 11.2  # M√©dia amostral
    Œº‚ÇÄ = 10.0  # M√©dia sob H‚ÇÄ
    s = 2.4    # Desvio padr√£o amostral
    n = 36     # Tamanho da amostra
    Œ± = 0.05   # N√≠vel de signific√¢ncia
    
    # Estat√≠stica t
    t_stat = (xÃÑ - Œº‚ÇÄ)/(s/‚àön)
    
    # Valor cr√≠tico
    t_crit = quantile(TDist(n-1), 1-Œ±/2)
    
    # Valor-p
    p_valor = 2 * (1 - cdf(TDist(n-1), abs(t_stat)))
    
    println("Teste t para Tempo de Atendimento")
    println("--------------------------------")
    println("Estat√≠stica t = ", round(t_stat, digits=4))
    println("Valor cr√≠tico = ¬±", round(t_crit, digits=4))
    println("Valor-p = ", round(p_valor, digits=4))
end

teste_tempo_atendimento()</code></pre>
  </div>
</div>

### 5.2 Teste de Independ√™ncia

> **Problema**: Em um estudo sobre a rela√ß√£o entre g√™nero e prefer√™ncia por tipo de exerc√≠cio f√≠sico, foram coletados os seguintes dados:

|            | Muscula√ß√£o | Cardio | Yoga |
|------------|------------|---------|------|
| Masculino  | 30         | 15      | 5    |
| Feminino   | 20         | 25      | 15   |

Teste se h√° independ√™ncia entre g√™nero e prefer√™ncia por exerc√≠cio ao n√≠vel de 5% de signific√¢ncia.

**Solu√ß√£o**:

1. Hip√≥teses:
   - $$H_0$$: G√™nero e prefer√™ncia s√£o independentes
   - $$H_1$$: Existe associa√ß√£o entre g√™nero e prefer√™ncia

2. Frequ√™ncias esperadas:
   $$E_{ij} = \frac{(total_{\text{linha } i})(total_{\text{coluna } j})}{total_{\text{geral}}}$$

3. Estat√≠stica qui-quadrado:
   $$\chi^2 = \sum_{i=1}^r \sum_{j=1}^c \frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$

<div class="code-container">
  <div class="code-header">
    <div class="code-lang">julia</div>
    <div style="flex-grow: 1;"></div>
    <button class="copy-button" onclick="copyCode(this)">
      <i class="bi bi-clipboard"></i>Copiar
    </button>
  </div>
  <div class="code-content">
    <pre><code>function teste_independencia()
    # Dados observados
    O = [30 15 5;
         20 25 15]
    
    # Totais
    n = sum(O)
    r_tot = sum(O, dims=2)
    c_tot = sum(O, dims=1)
    
    # Frequ√™ncias esperadas
    E = (r_tot * c_tot) / n
    
    # Estat√≠stica qui-quadrado
    œá¬≤ = sum((O .- E).^2 ./ E)
    
    # Graus de liberdade
    gl = (size(O,1)-1) * (size(O,2)-1)
    
    # Valor-p
    p_valor = 1 - cdf(Chisq(gl), œá¬≤)
    
    println("Teste Qui-quadrado de Independ√™ncia")
    println("---------------------------------")
    println("Estat√≠stica œá¬≤ = ", round(œá¬≤, digits=4))
    println("Graus de liberdade = ", gl)
    println("Valor-p = ", round(p_valor, digits=4))
end

teste_independencia()</code></pre>
  </div>
</div>

## 6. Considera√ß√µes Pr√°ticas

### 6.1 Pressupostos

1. **Normalidade**
   - Teste de Shapiro-Wilk
   - QQ-plot

2. **Independ√™ncia**
   - Aleatoriedade da amostra
   - Aus√™ncia de autocorrela√ß√£o

3. **Homocedasticidade**
   - Teste de Levene
   - Teste F

### 6.2 Tamanho da Amostra

O tamanho da amostra afeta:
- Poder do teste
- Precis√£o das estimativas
- Validade dos pressupostos

## 7. Intervalos de Confian√ßa e Testes de Hip√≥tese

### 7.1 Rela√ß√£o com Intervalos de Confian√ßa

Os intervalos de confian√ßa e testes de hip√≥tese s√£o complementares:
- Um intervalo de confian√ßa de (1-Œ±)% corresponde a todos os valores de Œº‚ÇÄ que n√£o seriam rejeitados em um teste de n√≠vel Œ±
- O intervalo fornece mais informa√ß√£o que o teste, pois indica a faixa de valores plaus√≠veis para o par√¢metro

### 7.2 Constru√ß√£o de Intervalos

Para uma m√©dia populacional:

$$IC_{1-\alpha} = \bar{x} \pm t_{\alpha/2, n-1} \frac{s}{\sqrt{n}}$$

<div class="code-container">
  <div class="code-header">
    <div class="code-lang">julia</div>
    <div style="flex-grow: 1;"></div>
    <button class="copy-button" onclick="copyCode(this)">
      <i class="bi bi-clipboard"></i>Copiar
    </button>
  </div>
  <div class="code-content">
    <pre><code>function calcular_ic_media()
    # Dados
    dados = randn(30) .+ 2  # Amostra com m√©dia ‚âà 2
    Œ± = 0.05
    
    # Estat√≠sticas
    xÃÑ = mean(dados)
    s = std(dados)
    n = length(dados)
    
    # Valor cr√≠tico t
    t_crit = quantile(TDist(n-1), 1-Œ±/2)
    
    # Intervalo de confian√ßa
    margem_erro = t_crit * (s/‚àön)
    ic_inf = xÃÑ - margem_erro
    ic_sup = xÃÑ + margem_erro
    
    println("Intervalo de Confian√ßa (95%)")
    println("----------------------------")
    println("Limite inferior: ", round(ic_inf, digits=4))
    println("Limite superior: ", round(ic_sup, digits=4))
end

calcular_ic_media()</code></pre>
  </div>
</div>

## 8. Exemplos Pr√°ticos Adicionais

### 8.1 Teste para Propor√ß√£o

> **Problema**: Uma empresa de marketing digital afirma que sua nova estrat√©gia de e-mail marketing tem taxa de convers√£o de 15%. Em uma amostra de 200 e-mails enviados, 40 resultaram em convers√£o. Teste esta afirma√ß√£o ao n√≠vel de 5% de signific√¢ncia.

**Solu√ß√£o**:

1. Hip√≥teses:
   - H‚ÇÄ: p = 0,15
   - H‚ÇÅ: p ‚â† 0,15

2. Estat√≠stica de teste:
   $$Z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}$$

<div class="code-container">
  <div class="code-header">
    <div class="code-lang">julia</div>
    <div style="flex-grow: 1;"></div>
    <button class="copy-button" onclick="copyCode(this)">
      <i class="bi bi-clipboard"></i>Copiar
    </button>
  </div>
  <div class="code-content">
    <pre><code>function teste_proporcao()
    # Dados
    n = 200        # Tamanho da amostra
    x = 40         # Sucessos
    p‚ÇÄ = 0.15      # Propor√ß√£o sob H‚ÇÄ
    Œ± = 0.05       # N√≠vel de signific√¢ncia
    
    # Propor√ß√£o amostral
    pÃÇ = x/n
    
    # Estat√≠stica Z
    z_stat = (pÃÇ - p‚ÇÄ)/‚àö(p‚ÇÄ*(1-p‚ÇÄ)/n)
    
    # Valor-p
    p_valor = 2 * (1 - cdf(Normal(), abs(z_stat)))
    
    println("Teste Z para Propor√ß√£o")
    println("---------------------")
    println("Propor√ß√£o amostral = ", round(pÃÇ, digits=4))
    println("Estat√≠stica Z = ", round(z_stat, digits=4))
    println("Valor-p = ", round(p_valor, digits=4))
end

teste_proporcao()</code></pre>
  </div>
</div>

### 8.2 Teste de Correla√ß√£o

> **Problema**: Queremos verificar se existe correla√ß√£o significativa entre as horas de estudo e as notas dos alunos.

<div class="code-container">
  <div class="code-header">
    <div class="code-lang">julia</div>
    <div style="flex-grow: 1;"></div>
    <button class="copy-button" onclick="copyCode(this)">
      <i class="bi bi-clipboard"></i>Copiar
    </button>
  </div>
  <div class="code-content">
    <pre><code>function teste_correlacao()
    # Dados simulados
    horas = [2, 3, 4, 3, 5, 6, 4, 5, 6, 7]
    notas = [65, 70, 75, 68, 80, 85, 72, 78, 88, 90]
    
    # Coeficiente de correla√ß√£o
    r = cor(horas, notas)
    
    # Estat√≠stica t
    n = length(horas)
    t_stat = r * ‚àö((n-2)/(1-r^2))
    
    # Valor-p
    p_valor = 2 * (1 - cdf(TDist(n-2), abs(t_stat)))
    
    println("Teste de Correla√ß√£o")
    println("------------------")
    println("Correla√ß√£o = ", round(r, digits=4))
    println("Estat√≠stica t = ", round(t_stat, digits=4))
    println("Valor-p = ", round(p_valor, digits=4))
end

teste_correlacao()</code></pre>
  </div>
</div>

## 9. Erros Comuns e Boas Pr√°ticas

### 9.1 Erros Comuns

1. **Interpreta√ß√£o Incorreta do Valor-p**
   - O valor-p N√ÉO √© a probabilidade de H‚ÇÄ ser verdadeira
   - O valor-p √© a probabilidade de obter dados t√£o ou mais extremos que os observados, assumindo H‚ÇÄ verdadeira

2. **Confus√£o entre Signific√¢ncia Estat√≠stica e Pr√°tica**
   - Signific√¢ncia estat√≠stica n√£o implica relev√¢ncia pr√°tica
   - Com amostras muito grandes, diferen√ßas pequenas podem ser estatisticamente significativas

3. **M√∫ltiplos Testes sem Corre√ß√£o**
   - Realizar m√∫ltiplos testes aumenta a chance de erro tipo I
   - Use corre√ß√µes como Bonferroni ou controle FDR

### 9.2 Boas Pr√°ticas

1. **Planejamento do Estudo**
   - Defina hip√≥teses antes da coleta de dados
   - Calcule o tamanho da amostra necess√°rio
   - Estabele√ßa crit√©rios de signific√¢ncia pr√°tica

2. **An√°lise de Dados**
   - Verifique pressupostos antes do teste
   - Use visualiza√ß√µes para complementar a an√°lise
   - Reporte intervalos de confian√ßa junto com valores-p

3. **Comunica√ß√£o dos Resultados**
   - Apresente estat√≠sticas descritivas
   - Reporte tamanhos de efeito
   - Discuta limita√ß√µes do estudo

## 10. Recursos Adicionais

### 10.1 Ferramentas Online

1. [Calculadora de Poder Estat√≠stico](https://www.powerandsamplesize.com/)
2. [Seletor de Teste Estat√≠stico](https://stats.idre.ucla.edu/other/mult-pkg/whatstat/)
3. [Visualizador de Distribui√ß√µes](https://seeing-theory.brown.edu/probability-distributions/index.html)

### 10.2 Pacotes Estat√≠sticos

1. **R**
   - stats
   - pwr
   - coin

2. **Python**
   - scipy.stats
   - statsmodels
   - pingouin

3. **Julia**
   - HypothesisTests.jl
   - StatisticalTests.jl
   - Power.jl

## Refer√™ncias Adicionais

6. Wasserman, L. **All of Statistics: A Concise Course in Statistical Inference**. Springer, 2004.
7. Lehmann, E. L.; Romano, J. P. **Testing Statistical Hypotheses**. 3¬™ ed. Springer, 2005.
8. Rice, J. A. **Mathematical Statistics and Data Analysis**. 3¬™ ed. Thomson Brooks/Cole, 2007.
9. Efron, B.; Hastie, T. **Computer Age Statistical Inference**. Cambridge University Press, 2016.
10. Good, P. I.; Hardin, J. W. **Common Errors in Statistics (and How to Avoid Them)**. 4¬™ ed. Wiley, 2012.

## 11. Guia para Escolha do Teste Estat√≠stico

### 11.1 √Årvore de Decis√£o

![√Årvore de decis√£o para escolha de testes]({{ site.baseurl }}/assets/images/arvore-testes.png){:style="max-width: 600px; display: block; margin: 0 auto;"}
<div class="image-caption" style="text-align: center;">Figura: √Årvore de decis√£o para sele√ß√£o do teste estat√≠stico apropriado</div>

### 11.2 Crit√©rios de Sele√ß√£o

1. **Tipo de Vari√°vel**
   
   | Tipo de Vari√°vel | Exemplos | Testes Apropriados |
   |------------------|----------|-------------------|
   | Nominal | G√™nero, Cor | Qui-quadrado, Teste exato de Fisher |
   | Ordinal | Escala Likert | Mann-Whitney, Kruskal-Wallis |
   | Intervalar/Raz√£o | Altura, Peso | Teste t, ANOVA |

2. **N√∫mero de Grupos**
   
   | N√∫mero de Grupos | Param√©trico | N√£o-Param√©trico |
   |-----------------|-------------|-----------------|
   | 2 grupos independentes | Teste t independente | Mann-Whitney |
   | 2 grupos pareados | Teste t pareado | Wilcoxon |
   | > 2 grupos independentes | ANOVA | Kruskal-Wallis |
   | > 2 grupos pareados | ANOVA medidas repetidas | Friedman |

3. **Pressupostos dos Testes**

   <div style="border-left: 4px solid #4CAF50; padding: 0.5em; background-color: #e8f5e9;">
   <strong>üîç Verifica√ß√£o de Pressupostos:</strong>
   
   - Normalidade: Shapiro-Wilk ou Kolmogorov-Smirnov
   - Homocedasticidade: Levene ou Bartlett
   - Independ√™ncia: Durbin-Watson
   </div>

### 11.3 Fluxograma de Decis√£o por Objetivo

#### 11.3.1 Compara√ß√£o de M√©dias/Medianas

```mermaid
graph TD
    A[Dados Num√©ricos] --> B{Normal?}
    B -->|Sim| C{Quantos grupos?}
    B -->|N√£o| D{Quantos grupos?}
    C -->|2 grupos| E{Pareado?}
    C -->|>2 grupos| F{Pareado?}
    D -->|2 grupos| G{Pareado?}
    D -->|>2 grupos| H{Pareado?}
    E -->|Sim| I[Teste t pareado]
    E -->|N√£o| J[Teste t independente]
    F -->|Sim| K[ANOVA medidas repetidas]
    F -->|N√£o| L[ANOVA one-way]
    G -->|Sim| M[Wilcoxon]
    G -->|N√£o| N[Mann-Whitney]
    H -->|Sim| O[Friedman]
    H -->|N√£o| P[Kruskal-Wallis]
```

#### 11.3.2 An√°lise de Rela√ß√µes

```mermaid
graph TD
    A[Tipo de Rela√ß√£o] --> B{Vari√°veis Num√©ricas?}
    B -->|Ambas| C{Normal?}
    B -->|Uma Categ√≥rica| D[An√°lise de Grupos]
    B -->|Ambas Categ√≥ricas| E[Qui-quadrado/Fisher]
    C -->|Sim| F[Correla√ß√£o de Pearson]
    C -->|N√£o| G[Correla√ß√£o de Spearman]
    D --> H{Normal?}
    H -->|Sim| I[Teste t/ANOVA]
    H -->|N√£o| J[Mann-Whitney/Kruskal-Wallis]
```

### 11.4 Tabela de Decis√£o R√°pida

| Objetivo | Condi√ß√µes | Teste Recomendado |
|----------|-----------|-------------------|
| Comparar m√©dia com valor de refer√™ncia | Normal | Teste t uma amostra |
| Comparar m√©dia com valor de refer√™ncia | N√£o normal | Wilcoxon uma amostra |
| Comparar duas m√©dias (independentes) | Normal + Vari√¢ncias iguais | Teste t independente |
| Comparar duas m√©dias (independentes) | Normal + Vari√¢ncias diferentes | Welch t-test |
| Comparar duas m√©dias (pareadas) | Normal | Teste t pareado |
| Comparar > 2 m√©dias | Normal + Homoced√°stico | ANOVA |
| Comparar propor√ß√µes | n grande | Teste Z propor√ß√µes |
| Comparar propor√ß√µes | n pequeno | Teste exato de Fisher |
| Verificar independ√™ncia | Categ√≥ricas | Qui-quadrado |
| Avaliar correla√ß√£o | Normal bivariada | Pearson |
| Avaliar correla√ß√£o | N√£o normal | Spearman |

### 11.5 Exemplos Pr√°ticos de Sele√ß√£o

1. **Exemplo: Efic√°cia de Medicamento**
   - Vari√°vel: Press√£o arterial (num√©rica)
   - Grupos: Antes e depois (pareado)
   - Distribui√ß√£o: Normal
   - **Teste escolhido**: Teste t pareado

2. **Exemplo: Prefer√™ncia por Marca**
   - Vari√°vel: Escolha de marca (categ√≥rica)
   - Grupos: M√∫ltiplas marcas
   - **Teste escolhido**: Qui-quadrado

<div class="code-container">
  <div class="code-header">
    <div class="code-lang">julia</div>
    <div style="flex-grow: 1;"></div>
    <button class="copy-button" onclick="copyCode(this)">
      <i class="bi bi-clipboard"></i>Copiar
    </button>
  </div>
  <div class="code-content">
    <pre><code>using HypothesisTests

function exemplo_selecao_teste()
    # Exemplo 1: Teste t pareado
    antes = [120, 122, 118, 125, 124]
    depois = [115, 118, 112, 120, 119]
    
    # Teste de normalidade primeiro
    println("Teste de Normalidade (diferen√ßas):")
    dif = depois .- antes
    normal_test = ShapiroWilkTest(dif)
    println("p-valor = ", round(pvalue(normal_test), digits=4))
    
    # Se normal, proceder com teste t pareado
    if pvalue(normal_test) > 0.05
        paired_test = OneSampleTTest(dif)
        println("\nTeste t Pareado:")
        println("Estat√≠stica t = ", round(test_statistic(paired_test), digits=4))
        println("p-valor = ", round(pvalue(paired_test), digits=4))
    else
        # Se n√£o normal, usar Wilcoxon
        wilcox_test = SignedRankTest(depois, antes)
        println("\nTeste de Wilcoxon:")
        println("p-valor = ", round(pvalue(wilcox_test), digits=4))
    end
end

exemplo_selecao_teste()</code></pre>
  </div>
</div>

### 11.6 Considera√ß√µes Importantes

1. **Tamanho da Amostra**
   - n < 30: Verificar normalidade √© crucial
   - n ‚â• 30: Testes param√©tricos s√£o mais robustos

2. **Viola√ß√£o de Pressupostos**
   - Leve: Testes param√©tricos ainda s√£o robustos
   - Severa: Optar por alternativas n√£o-param√©tricas

3. **Poder Estat√≠stico**
   - Testes param√©tricos: Maior poder se pressupostos atendidos
   - Testes n√£o-param√©tricos: Mais seguros se d√∫vida sobre pressupostos

4. **Interpretabilidade**
   - Considerar a facilidade de interpreta√ß√£o
   - Balancear rigor estat√≠stico com praticidade

## 12. Testes Param√©tricos vs. N√£o Param√©tricos

### 12.1 Testes Param√©tricos

Os testes param√©tricos s√£o procedimentos estat√≠sticos que assumem que os dados seguem uma distribui√ß√£o de probabilidade espec√≠fica (geralmente a distribui√ß√£o normal) e fazem infer√™ncias sobre os par√¢metros dessa distribui√ß√£o.

#### 12.1.1 Caracter√≠sticas Principais

1. **Pressupostos**
   - Normalidade dos dados
   - Homogeneidade das vari√¢ncias (homocedasticidade)
   - Independ√™ncia das observa√ß√µes
   - Vari√°veis cont√≠nuas ou intervalares

2. **Vantagens**
   - Maior poder estat√≠stico quando os pressupostos s√£o atendidos
   - Estimativas mais precisas
   - Capacidade de fazer infer√™ncias sobre par√¢metros populacionais

3. **Exemplos de Testes Param√©tricos**

   | Teste | Uso | Pressuposto Principal |
   |-------|-----|----------------------|
   | Teste t | Compara√ß√£o de m√©dias | Normalidade |
   | ANOVA | Compara√ß√£o de m√∫ltiplas m√©dias | Normalidade e homocedasticidade |
   | Correla√ß√£o de Pearson | Associa√ß√£o linear | Normalidade bivariada |
   | Regress√£o Linear | Rela√ß√£o entre vari√°veis | Normalidade dos res√≠duos |

#### 12.1.2 Verifica√ß√£o de Pressupostos

<div class="code-container">
  <div class="code-header">
    <div class="code-lang">julia</div>
    <div style="flex-grow: 1;"></div>
    <button class="copy-button" onclick="copyCode(this)">
      <i class="bi bi-clipboard"></i>Copiar
    </button>
  </div>
  <div class="code-content">
    <pre><code>using HypothesisTests
using Statistics

function verificar_pressupostos()
    # Dados simulados
    dados = randn(30) .* 2 .+ 1
    
    # 1. Teste de Normalidade
    normalidade = ShapiroWilkTest(dados)
    
    # 2. Teste de Homocedasticidade (entre dois grupos)
    grupo1 = randn(20) .* 2
    grupo2 = randn(20) .* 2
    homog = VarianceFTest(grupo1, grupo2)
    
    println("Verifica√ß√£o de Pressupostos")
    println("---------------------------")
    println("Teste de Normalidade:")
    println("Estat√≠stica W = ", round(test_statistic(normalidade), digits=4))
    println("p-valor = ", round(pvalue(normalidade), digits=4))
    println("\nTeste de Homocedasticidade:")
    println("Estat√≠stica F = ", round(test_statistic(homog), digits=4))
    println("p-valor = ", round(pvalue(homog), digits=4))
end

verificar_pressupostos()</code></pre>
  </div>
</div>

### 12.2 Testes N√£o Param√©tricos

Os testes n√£o param√©tricos s√£o procedimentos estat√≠sticos que n√£o exigem pressupostos sobre a distribui√ß√£o dos dados. S√£o tamb√©m conhecidos como "testes livres de distribui√ß√£o".

#### 12.2.1 Caracter√≠sticas Principais

1. **Vantagens**
   - Mais flex√≠veis quanto √† distribui√ß√£o dos dados
   - Robustos a outliers
   - Aplic√°veis a dados ordinais
   - √öteis para amostras pequenas

2. **Limita√ß√µes**
   - Menor poder estat√≠stico que testes param√©tricos
   - N√£o fazem infer√™ncias sobre par√¢metros espec√≠ficos
   - Podem perder informa√ß√£o ao usar ranks

3. **Exemplos de Testes N√£o Param√©tricos**

   | Teste N√£o Param√©trico | Equivalente Param√©trico | Uso |
   |----------------------|------------------------|-----|
   | Mann-Whitney U | Teste t independente | Comparar dois grupos |
   | Wilcoxon | Teste t pareado | Comparar medidas repetidas |
   | Kruskal-Wallis | ANOVA one-way | Comparar m√∫ltiplos grupos |
   | Spearman | Correla√ß√£o de Pearson | Correla√ß√£o por ranks |

#### 12.2.2 Exemplo Comparativo

<div class="code-container">
  <div class="code-header">
    <div class="code-lang">julia</div>
    <div style="flex-grow: 1;"></div>
    <button class="copy-button" onclick="copyCode(this)">
      <i class="bi bi-clipboard"></i>Copiar
    </button>
  </div>
  <div class="code-content">
    <pre><code>function comparar_testes()
    # Dados n√£o normais (distribui√ß√£o exponencial)
    grupo1 = rand(Exponential(1), 20)
    grupo2 = rand(Exponential(1.5), 20)
    
    # Teste param√©trico (t)
    teste_t = UnequalVarianceTTest(grupo1, grupo2)
    
    # Teste n√£o param√©trico (Mann-Whitney)
    teste_mw = MannWhitneyUTest(grupo1, grupo2)
    
    println("Compara√ß√£o entre Testes")
    println("----------------------")
    println("Teste t:")
    println("Estat√≠stica t = ", round(test_statistic(teste_t), digits=4))
    println("p-valor = ", round(pvalue(teste_t), digits=4))
    println("\nTeste de Mann-Whitney:")
    println("Estat√≠stica U = ", round(test_statistic(teste_mw), digits=4))
    println("p-valor = ", round(pvalue(teste_mw), digits=4))
end

comparar_testes()</code></pre>
  </div>
</div>

### 12.3 Quando Usar Cada Tipo de Teste?

#### 12.3.1 Use Testes Param√©tricos Quando:

1. **Dados Atendem aos Pressupostos**
   - Distribui√ß√£o normal ou aproximadamente normal
   - Vari√¢ncias homog√™neas
   - Tamanho amostral adequado (n ‚â• 30)

2. **Precis√£o √© Crucial**
   - Necessidade de estimativas precisas
   - Infer√™ncias sobre par√¢metros populacionais
   - Poder estat√≠stico √© prioridade

#### 12.3.2 Use Testes N√£o Param√©tricos Quando:

1. **Viola√ß√£o de Pressupostos**
   - Dados n√£o normais
   - Heteroscedasticidade
   - Presen√ßa de outliers significativos

2. **Caracter√≠sticas dos Dados**
   - Amostra pequena (n < 30)
   - Dados ordinais ou rankings
   - Distribui√ß√£o muito assim√©trica

<div style="border-left: 4px solid #FFA500; padding: 0.5em; background-color: #FFF3E0;">
  <strong>‚ö†Ô∏è Dica Importante:</strong><br>
  Em caso de d√∫vida entre teste param√©trico e n√£o param√©trico:
  1. Verifique os pressupostos rigorosamente
  2. Se houver viola√ß√£o moderada, o teste param√©trico ainda pode ser usado
  3. Se houver viola√ß√£o severa, opte pelo teste n√£o param√©trico
  4. Considere reportar ambos os resultados se forem divergentes
</div>

### 12.4 Tabela Comparativa Detalhada

| Aspecto | Testes Param√©tricos | Testes N√£o Param√©tricos |
|---------|-------------------|------------------------|
| Pressupostos | Mais rigorosos | Mais flex√≠veis |
| Poder Estat√≠stico | Maior (quando pressupostos atendidos) | Menor |
| Robustez | Menor | Maior |
| Interpreta√ß√£o | Mais direta | Menos intuitiva |
| Tamanho Amostral | Prefer√≠vel n ‚â• 30 | Funciona bem com n < 30 |
| Tipo de Dados | Intervalares/Raz√£o | Qualquer tipo |
| Outliers | Sens√≠vel | Robusto |
| Precis√£o | Maior | Menor |

### 12.5 Exemplos de Aplica√ß√£o

1. **Cen√°rio: Dados Normais, n = 50**
   - Escolha: Teste param√©trico
   - Raz√£o: Pressupostos atendidos, maior poder

2. **Cen√°rio: Dados Assim√©tricos, n = 15**
   - Escolha: Teste n√£o param√©trico
   - Raz√£o: Amostra pequena, n√£o normalidade

3. **Cen√°rio: Escala Likert**
   - Escolha: Teste n√£o param√©trico
   - Raz√£o: Dados ordinais

4. **Cen√°rio: Medidas F√≠sicas, n = 100**
   - Escolha: Teste param√©trico
   - Raz√£o: Dados cont√≠nuos, amostra grande
